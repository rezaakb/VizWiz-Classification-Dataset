{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoQaT5Sk5qOf"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfSsM2Xl492v"
   },
   "source": [
    "In this notebook, we download the dataset and install the necessary packages. Then, we will produce predictions of the VGG-19 model on our dataset. Finally, we generate a file that you can upload to the EvalAI server for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvHsfrO5x_zC"
   },
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyjPLJKlxaew"
   },
   "source": [
    "#### Install timm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCgwLoH7vTR6",
    "outputId": "f2a514b9-2511-455e-f03f-58e9127d3ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting timm\n",
      "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n",
      "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Installing collected packages: huggingface-hub, timm\n",
      "Successfully installed huggingface-hub-0.11.1 timm-0.6.12\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k28aHolGxWo6"
   },
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFx7yFf23Ru4"
   },
   "source": [
    "In this stage, we want to download all images available in VizWiz dataset. Downloading images and annotations may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_DmRRx2vWT7",
    "outputId": "bb292b02-f879-47c1-b642-b3c32f6ca832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-11 08:28:52--  https://vizwiz.cs.colorado.edu/VizWiz_final/images/train.zip\n",
      "Resolving vizwiz.cs.colorado.edu (vizwiz.cs.colorado.edu)... 198.59.7.50\n",
      "Connecting to vizwiz.cs.colorado.edu (vizwiz.cs.colorado.edu)|198.59.7.50|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11298421598 (11G) [application/zip]\n",
      "Saving to: ‘train.zip’\n",
      "\n",
      "train.zip           100%[===================>]  10.52G  15.8MB/s    in 11m 34s \n",
      "\n",
      "2023-01-11 08:40:27 (15.5 MB/s) - ‘train.zip’ saved [11298421598/11298421598]\n",
      "\n",
      "--2023-01-11 08:40:27--  https://vizwiz.cs.colorado.edu/VizWiz_final/images/val.zip\n",
      "Reusing existing connection to vizwiz.cs.colorado.edu:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3488913457 (3.2G) [application/zip]\n",
      "Saving to: ‘val.zip’\n",
      "\n",
      "val.zip             100%[===================>]   3.25G  15.7MB/s    in 3m 35s  \n",
      "\n",
      "2023-01-11 08:44:01 (15.5 MB/s) - ‘val.zip’ saved [3488913457/3488913457]\n",
      "\n",
      "--2023-01-11 08:44:01--  https://vizwiz.cs.colorado.edu/VizWiz_final/images/test.zip\n",
      "Reusing existing connection to vizwiz.cs.colorado.edu:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3975272799 (3.7G) [application/zip]\n",
      "Saving to: ‘test.zip’\n",
      "\n",
      "test.zip            100%[===================>]   3.70G  15.7MB/s    in 4m 6s   \n",
      "\n",
      "2023-01-11 08:48:07 (15.4 MB/s) - ‘test.zip’ saved [3975272799/3975272799]\n",
      "\n",
      "--2023-01-11 08:48:07--  http://%5C/\n",
      "Resolving \\\\ (\\\\)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘\\\\’\n",
      "FINISHED --2023-01-11 08:48:07--\n",
      "Total wall clock time: 19m 15s\n",
      "Downloaded: 3 files, 17G in 19m 14s (15.5 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p dataset/images predictions\n",
    "!wget https://vizwiz.cs.colorado.edu/VizWiz_final/images/train.zip \\\n",
    "      https://vizwiz.cs.colorado.edu/VizWiz_final/images/val.zip \\\n",
    "      https://vizwiz.cs.colorado.edu/VizWiz_final/images/test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Nd8TgGrq2MBa"
   },
   "outputs": [],
   "source": [
    "!unzip -q -o train.zip -d dataset/images\n",
    "!unzip -q -o val.zip -d dataset/images\n",
    "!unzip -q -o test.zip -d dataset/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DXzJ0gjM4H2J"
   },
   "outputs": [],
   "source": [
    "!rm train.zip val.zip test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHpADdfS9GXe"
   },
   "outputs": [],
   "source": [
    "!mv -v dataset/images/train/* dataset/images/\n",
    "!mv -v dataset/images/val/* dataset/images/\n",
    "!mv -v dataset/images/test/* dataset/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVWg6brFyK1i"
   },
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdWGQB2ZxP4o"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "qK4HAU7jvIkV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySt0VVvqwbj9"
   },
   "source": [
    "#### Set variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "2iomVcQhvJ3E"
   },
   "outputs": [],
   "source": [
    "ann_path = 'dataset/annotations.json'\n",
    "images_path = 'dataset/images'\n",
    "prediction_path = 'predictions/'\n",
    "model_name = 'vgg19'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAl97lEMwjNA"
   },
   "source": [
    "#### Load annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "3Eow13OHwKVm"
   },
   "outputs": [],
   "source": [
    "annotations = json.load(open(ann_path))    \n",
    "indices_in_1k = [d['id'] for d in annotations['categories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cFQeOsuwnjI"
   },
   "source": [
    "#### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "GFS6FYp0wrmx"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tg8jyuAwxKw"
   },
   "source": [
    "#### Create dataset class and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "137pPGf9wzfL"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "    ])       \n",
    "\n",
    "class VizWizClassification(Dataset):\n",
    "    def __init__(self, annotations, transform=None):\n",
    "        self.images = [os.path.join(images_path,str(path)) for path in annotations['images']]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.images[idx].split(\"/\")[2]\n",
    "    \n",
    "dataset = VizWizClassification(annotations,test_transform)\n",
    "vizwiz_loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWeIH-miw2vA"
   },
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmJ9MZS-w9K-",
    "outputId": "c7b4fa8e-54a5-40cb-b8e7-916a3c3a7471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (pre_logits): ConvMlp(\n",
       "    (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(model_name, pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHhEcb0QxGl2"
   },
   "source": [
    "#### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "zqUdCiEXy9jX"
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "with torch.no_grad():\n",
    "    for images, images_path in vizwiz_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)[:,indices_in_1k]\n",
    "        pred = list(outputs.data.max(1)[1].cpu())\n",
    "        for i in range(len(pred)):\n",
    "                results[images_path[i]] = indices_in_1k[pred[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6KngDktzAf5"
   },
   "source": [
    "### Save the prediction file for EvalAI server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "oCcttfFfy_fT"
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(prediction_path, datetime.now().strftime(\"prediction-%m-%d-%Y-%H:%M:%S.json\"))\n",
    "with open(file_path, 'w') as outfile:\n",
    "    json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLjHu5VP_eoW"
   },
   "source": [
    "Now you can upload this file on EvalAI server."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
